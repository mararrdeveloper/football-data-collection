{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import calibrate_train_clfs, load_data, get_baseline, print_results, run_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEEEP\n",
      "LENGTH1180\n"
     ]
    }
   ],
   "source": [
    "keep_columns =  ['IsTraining','FTR', 'Div', 'Date', 'HomeTeam', 'AwayTeam', \n",
    "    'away_away_team_corners_against', 'away_away_team_corners_for',\t'away_away_team_goals_against',\t'away_away_team_goals_for',\t\n",
    "    'away_away_team_possession',\t'away_away_team_shotsoff_against',\t'away_away_team_shotsoff_for',\t'away_away_team_shotson_against',\n",
    "    \t'away_away_team_shotson_for',\t'away_direct_team_corners_against',\t'away_direct_team_corners_for',\t'away_direct_team_goals_against',\n",
    "        'away_direct_team_goals_for',\t'away_direct_team_possession',\t'away_direct_team_shotsoff_against',\t'away_direct_team_shotsoff_for',\n",
    "        'away_direct_team_shotson_against',\t'away_direct_team_shotson_for',\t'home_direct_team_corners_against',\t'home_direct_team_corners_for',\t\n",
    "        'home_direct_team_goals_against',\t'home_direct_team_goals_for',\t'home_direct_team_possession',\t'home_direct_team_shotsoff_against',\n",
    "        'home_direct_team_shotsoff_for',\t'home_direct_team_shotson_against',\t'home_direct_team_shotson_for',\t\n",
    "        'home_home_team_corners_against',\t'home_home_team_corners_for',\t'home_home_team_goals_against',\t'home_home_team_goals_for',\t\n",
    "        'home_home_team_possession',\t'home_home_team_shotsoff_against',\t'home_home_team_shotsoff_for',\t'home_home_team_shotson_against',\n",
    "                 'home_home_team_shotson_for','Referee' \n",
    "]\n",
    " \n",
    "drop_columns = [\n",
    "    'B365H', 'B365D', 'B365A',\n",
    "    'AC', 'AF', 'AR', 'AS', 'AST', 'AY', \n",
    "    'BWA', 'BWD', 'BWH', 'Bb1X2', 'BbAH', 'BbAHh', 'BbAv<2.5', 'BbAv>2.5', 'BbAvA', 'BbAvAHA', \n",
    "    'BbAvAHH', 'BbAvD', 'BbAvH', 'BbMx<2.5', 'BbMx>2.5', 'BbMxA', 'BbMxAHA', 'BbMxAHH', 'BbMxD',\n",
    "    'BbMxH', 'BbOU', 'FTAG', \n",
    "    'HC', 'HF', 'HR', 'HS', 'HST', \n",
    "    'HTAG', 'HTHG', 'HTR', 'HY', 'IWA', 'IWD', 'IWH', \n",
    "    'LBA', 'LBD', 'LBH', 'PSA', 'PSCA', 'PSCD', 'PSCH', 'PSD', 'PSH', \n",
    "    'VCA', 'VCD', 'VCH', 'WHA', 'WHD', 'WHH', 'GoalFirstHalf', 'SHHG', 'SHAG', 'GoalSecondHalf','FTR','BothToScore',\n",
    "]\n",
    "\n",
    "#\n",
    "target_column = \"FTR\"\n",
    "drop_columns.remove(target_column)\n",
    "X,y = load_data(columns_to_drop=drop_columns, is_training=True, target_name=target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=y.values\n",
    "X=X.values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12,  activation='relu')) # input_dim=314,\n",
    "#   model.add(Bidirectional(LSTM(256,  return_sequences=True, dropout=0.1, recurrent_dropout=0.1,kernel_initializer=glorot_normal(seed=None)),name = 'BDLSTM1')) #Best = 300,0.25,0.25\n",
    "#    model.add(Dense(8, activation='relu'))\n",
    "#    model.add(Dense(1, activation='linear'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "#     # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mae', 'mse', f1_m], verbose=1)\n",
    "    #model.compile(loss='mse', optimizer='adam', metrics=['mse','mae']) \n",
    "    return model\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=10, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "295/295 [==============================] - 41s 138ms/step - loss: 3.8092 - acc: 0.3186 - mean_absolute_error: 0.4573 - mean_squared_error: 0.3513 - f1_m: 0.2294\n",
      "Epoch 2/10\n",
      "295/295 [==============================] - 1s 5ms/step - loss: 1.1269 - acc: 0.3932 - mean_absolute_error: 0.4381 - mean_squared_error: 0.2231 - f1_m: 0.0475\n",
      "Epoch 3/10\n",
      "295/295 [==============================] - 1s 4ms/step - loss: 1.0803 - acc: 0.4000 - mean_absolute_error: 0.4373 - mean_squared_error: 0.2185 - f1_m: 0.0316\n",
      "Epoch 4/10\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 1.0735 - acc: 0.4136 - mean_absolute_error: 0.4333 - mean_squared_error: 0.2169 - f1_m: 0.0395\n",
      "Epoch 5/10\n",
      "295/295 [==============================] - 2s 7ms/step - loss: 1.0771 - acc: 0.4068 - mean_absolute_error: 0.4363 - mean_squared_error: 0.2177 - f1_m: 0.0271\n",
      "Epoch 6/10\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 1.0671 - acc: 0.4034 - mean_absolute_error: 0.4322 - mean_squared_error: 0.2158 - f1_m: 0.0395\n",
      "Epoch 7/10\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 1.0784 - acc: 0.4102 - mean_absolute_error: 0.4337 - mean_squared_error: 0.2179 - f1_m: 0.0407\n",
      "Epoch 8/10\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 1.0645 - acc: 0.4169 - mean_absolute_error: 0.4316 - mean_squared_error: 0.2149 - f1_m: 0.0362\n",
      "Epoch 9/10\n",
      "295/295 [==============================] - 1s 4ms/step - loss: 1.0584 - acc: 0.4203 - mean_absolute_error: 0.4303 - mean_squared_error: 0.2138 - f1_m: 0.0452\n",
      "Epoch 10/10\n",
      "295/295 [==============================] - 1s 3ms/step - loss: 1.0564 - acc: 0.4169 - mean_absolute_error: 0.4285 - mean_squared_error: 0.2134 - f1_m: 0.0429\n",
      "295/295 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "590/590 [==============================] - 2s 4ms/step - loss: 2.3068 - acc: 0.3780 - mean_absolute_error: 0.4525 - mean_squared_error: 0.2661 - f1_m: 0.0825\n",
      "Epoch 2/10\n",
      "590/590 [==============================] - 3s 4ms/step - loss: 1.1225 - acc: 0.4407 - mean_absolute_error: 0.4399 - mean_squared_error: 0.2203 - f1_m: 0.0147\n",
      "Epoch 3/10\n",
      "590/590 [==============================] - 3s 6ms/step - loss: 1.0954 - acc: 0.4475 - mean_absolute_error: 0.4362 - mean_squared_error: 0.2178 - f1_m: 0.0198\n",
      "Epoch 4/10\n",
      "590/590 [==============================] - 2s 4ms/step - loss: 1.0753 - acc: 0.4458 - mean_absolute_error: 0.4336 - mean_squared_error: 0.2157 - f1_m: 0.0158\n",
      "Epoch 5/10\n",
      "590/590 [==============================] - 3s 4ms/step - loss: 1.0708 - acc: 0.4525 - mean_absolute_error: 0.4317 - mean_squared_error: 0.2145 - f1_m: 0.0203\n",
      "Epoch 6/10\n",
      "590/590 [==============================] - 2s 4ms/step - loss: 1.0705 - acc: 0.4492 - mean_absolute_error: 0.4313 - mean_squared_error: 0.2149 - f1_m: 0.0203\n",
      "Epoch 7/10\n",
      "590/590 [==============================] - 2s 4ms/step - loss: 1.0683 - acc: 0.4475 - mean_absolute_error: 0.4309 - mean_squared_error: 0.2145 - f1_m: 0.0181\n",
      "Epoch 8/10\n",
      "590/590 [==============================] - 3s 5ms/step - loss: 1.0687 - acc: 0.4492 - mean_absolute_error: 0.4300 - mean_squared_error: 0.2148 - f1_m: 0.0181\n",
      "Epoch 9/10\n",
      "590/590 [==============================] - 4s 7ms/step - loss: 1.0659 - acc: 0.4508 - mean_absolute_error: 0.4286 - mean_squared_error: 0.2142 - f1_m: 0.0158\n",
      "Epoch 10/10\n",
      "590/590 [==============================] - 3s 4ms/step - loss: 1.0650 - acc: 0.4492 - mean_absolute_error: 0.4287 - mean_squared_error: 0.2144 - f1_m: 0.0181\n",
      "295/295 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "885/885 [==============================] - 3s 4ms/step - loss: 2.3786 - acc: 0.4068 - mean_absolute_error: 0.4100 - mean_squared_error: 0.2800 - f1_m: 0.3446\n",
      "Epoch 2/10\n",
      "885/885 [==============================] - 3s 4ms/step - loss: 1.1479 - acc: 0.4814 - mean_absolute_error: 0.3855 - mean_squared_error: 0.2187 - f1_m: 0.3872\n",
      "Epoch 3/10\n",
      "885/885 [==============================] - 4s 5ms/step - loss: 1.0564 - acc: 0.5096 - mean_absolute_error: 0.3741 - mean_squared_error: 0.2054 - f1_m: 0.3944\n",
      "Epoch 4/10\n",
      "885/885 [==============================] - 3s 3ms/step - loss: 1.0190 - acc: 0.5164 - mean_absolute_error: 0.3682 - mean_squared_error: 0.1993 - f1_m: 0.4011\n",
      "Epoch 5/10\n",
      "885/885 [==============================] - 3s 3ms/step - loss: 0.9985 - acc: 0.5356 - mean_absolute_error: 0.3647 - mean_squared_error: 0.1933 - f1_m: 0.4049\n",
      "Epoch 6/10\n",
      "885/885 [==============================] - 3s 3ms/step - loss: 0.9424 - acc: 0.5593 - mean_absolute_error: 0.3543 - mean_squared_error: 0.1846 - f1_m: 0.4531\n",
      "Epoch 7/10\n",
      "885/885 [==============================] - 4s 4ms/step - loss: 0.9316 - acc: 0.5661 - mean_absolute_error: 0.3461 - mean_squared_error: 0.1810 - f1_m: 0.4625\n",
      "Epoch 8/10\n",
      "885/885 [==============================] - 4s 5ms/step - loss: 0.9114 - acc: 0.5751 - mean_absolute_error: 0.3406 - mean_squared_error: 0.1768 - f1_m: 0.4712\n",
      "Epoch 9/10\n",
      "885/885 [==============================] - 3s 3ms/step - loss: 0.8417 - acc: 0.6034 - mean_absolute_error: 0.3292 - mean_squared_error: 0.1647 - f1_m: 0.5107\n",
      "Epoch 10/10\n",
      "885/885 [==============================] - 2s 3ms/step - loss: 0.8213 - acc: 0.6226 - mean_absolute_error: 0.3218 - mean_squared_error: 0.1621 - f1_m: 0.5379\n",
      "295/295 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# #seed = 7\n",
    "# #numpy.random.seed(seed)\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=3)# max_train_size=100\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# #kfold = KFold(n_splits=10)\n",
    "# # shuffle=True, random_state=seed\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=tscv.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46779661, 0.4779661 , 0.61016949])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5186440677966102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics \n",
    "x = statistics.mean(results)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_calibrate, X_test, y_train_calibrate, y_test = train_test_split(X, y, test_size=0.20)\n",
    "X_train, X_calibrate, y_train, y_calibrate = train_test_split(X_train_calibrate, y_train_calibrate, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 944 samples, validate on 236 samples\n",
      "Epoch 1/30\n",
      "944/944 [==============================] - 1s 891us/step - loss: 4.1613 - acc: 0.3464 - mean_absolute_error: 0.4313 - mean_squared_error: 0.3411 - f1_m: 0.3218 - val_loss: 2.4166 - val_acc: 0.2881 - val_mean_absolute_error: 0.4686 - val_mean_squared_error: 0.3456 - val_f1_m: 0.2718\n",
      "Epoch 2/30\n",
      "944/944 [==============================] - 1s 565us/step - loss: 1.2422 - acc: 0.4206 - mean_absolute_error: 0.4248 - mean_squared_error: 0.2371 - f1_m: 0.2397 - val_loss: 2.6266 - val_acc: 0.2754 - val_mean_absolute_error: 0.4813 - val_mean_squared_error: 0.3812 - val_f1_m: 0.2642\n",
      "Epoch 3/30\n",
      "944/944 [==============================] - 0s 484us/step - loss: 1.1713 - acc: 0.4407 - mean_absolute_error: 0.4215 - mean_squared_error: 0.2292 - f1_m: 0.2323 - val_loss: 1.4260 - val_acc: 0.3347 - val_mean_absolute_error: 0.4383 - val_mean_squared_error: 0.2714 - val_f1_m: 0.2548\n",
      "Epoch 4/30\n",
      "944/944 [==============================] - 1s 665us/step - loss: 1.1409 - acc: 0.4523 - mean_absolute_error: 0.4169 - mean_squared_error: 0.2229 - f1_m: 0.2481 - val_loss: 1.1637 - val_acc: 0.5127 - val_mean_absolute_error: 0.3909 - val_mean_squared_error: 0.2197 - val_f1_m: 0.4498\n",
      "Epoch 5/30\n",
      "944/944 [==============================] - 0s 523us/step - loss: 1.1205 - acc: 0.4650 - mean_absolute_error: 0.4102 - mean_squared_error: 0.2186 - f1_m: 0.2652 - val_loss: 1.3048 - val_acc: 0.4576 - val_mean_absolute_error: 0.3907 - val_mean_squared_error: 0.2397 - val_f1_m: 0.4209\n",
      "Epoch 6/30\n",
      "944/944 [==============================] - 0s 480us/step - loss: 1.1059 - acc: 0.4735 - mean_absolute_error: 0.4065 - mean_squared_error: 0.2140 - f1_m: 0.2894 - val_loss: 1.4216 - val_acc: 0.4280 - val_mean_absolute_error: 0.3959 - val_mean_squared_error: 0.2527 - val_f1_m: 0.4288\n",
      "Epoch 7/30\n",
      "944/944 [==============================] - 1s 677us/step - loss: 1.1130 - acc: 0.4703 - mean_absolute_error: 0.4025 - mean_squared_error: 0.2152 - f1_m: 0.2840 - val_loss: 1.3809 - val_acc: 0.3898 - val_mean_absolute_error: 0.4211 - val_mean_squared_error: 0.2692 - val_f1_m: 0.3433\n",
      "Epoch 8/30\n",
      "944/944 [==============================] - 0s 486us/step - loss: 1.0632 - acc: 0.4905 - mean_absolute_error: 0.3973 - mean_squared_error: 0.2081 - f1_m: 0.3177 - val_loss: 1.4554 - val_acc: 0.5636 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.2282 - val_f1_m: 0.5625\n",
      "Epoch 9/30\n",
      "944/944 [==============================] - 0s 524us/step - loss: 1.0222 - acc: 0.5032 - mean_absolute_error: 0.3882 - mean_squared_error: 0.2006 - f1_m: 0.3534 - val_loss: 1.0109 - val_acc: 0.5381 - val_mean_absolute_error: 0.3643 - val_mean_squared_error: 0.1939 - val_f1_m: 0.5173\n",
      "Epoch 10/30\n",
      "944/944 [==============================] - 1s 839us/step - loss: 1.0151 - acc: 0.5032 - mean_absolute_error: 0.3842 - mean_squared_error: 0.1996 - f1_m: 0.3563 - val_loss: 1.0202 - val_acc: 0.5932 - val_mean_absolute_error: 0.3419 - val_mean_squared_error: 0.1894 - val_f1_m: 0.5688\n",
      "Epoch 11/30\n",
      "944/944 [==============================] - 1s 716us/step - loss: 1.0347 - acc: 0.5074 - mean_absolute_error: 0.3860 - mean_squared_error: 0.2011 - f1_m: 0.3607 - val_loss: 1.5303 - val_acc: 0.4322 - val_mean_absolute_error: 0.3848 - val_mean_squared_error: 0.2687 - val_f1_m: 0.4133\n",
      "Epoch 12/30\n",
      "944/944 [==============================] - 1s 775us/step - loss: 1.0265 - acc: 0.5064 - mean_absolute_error: 0.3823 - mean_squared_error: 0.1974 - f1_m: 0.3653 - val_loss: 1.1204 - val_acc: 0.4958 - val_mean_absolute_error: 0.3581 - val_mean_squared_error: 0.2097 - val_f1_m: 0.4871\n",
      "Epoch 13/30\n",
      "944/944 [==============================] - 1s 608us/step - loss: 1.0163 - acc: 0.5180 - mean_absolute_error: 0.3739 - mean_squared_error: 0.1943 - f1_m: 0.3895 - val_loss: 1.0075 - val_acc: 0.5805 - val_mean_absolute_error: 0.3271 - val_mean_squared_error: 0.1852 - val_f1_m: 0.5862\n",
      "Epoch 14/30\n",
      "944/944 [==============================] - 1s 844us/step - loss: 0.9892 - acc: 0.5265 - mean_absolute_error: 0.3724 - mean_squared_error: 0.1915 - f1_m: 0.3974 - val_loss: 1.0295 - val_acc: 0.5678 - val_mean_absolute_error: 0.3626 - val_mean_squared_error: 0.1998 - val_f1_m: 0.5251\n",
      "Epoch 15/30\n",
      "944/944 [==============================] - 1s 584us/step - loss: 0.9515 - acc: 0.5392 - mean_absolute_error: 0.3657 - mean_squared_error: 0.1856 - f1_m: 0.4112 - val_loss: 1.1959 - val_acc: 0.5805 - val_mean_absolute_error: 0.3177 - val_mean_squared_error: 0.2057 - val_f1_m: 0.5768\n",
      "Epoch 16/30\n",
      "944/944 [==============================] - 1s 549us/step - loss: 0.9792 - acc: 0.5371 - mean_absolute_error: 0.3688 - mean_squared_error: 0.1901 - f1_m: 0.3973 - val_loss: 1.0348 - val_acc: 0.5169 - val_mean_absolute_error: 0.3486 - val_mean_squared_error: 0.1961 - val_f1_m: 0.5103\n",
      "Epoch 17/30\n",
      "944/944 [==============================] - 1s 599us/step - loss: 0.9234 - acc: 0.5646 - mean_absolute_error: 0.3548 - mean_squared_error: 0.1795 - f1_m: 0.4602 - val_loss: 1.3543 - val_acc: 0.5381 - val_mean_absolute_error: 0.3173 - val_mean_squared_error: 0.2259 - val_f1_m: 0.5383\n",
      "Epoch 18/30\n",
      "944/944 [==============================] - 0s 489us/step - loss: 0.9261 - acc: 0.5424 - mean_absolute_error: 0.3562 - mean_squared_error: 0.1816 - f1_m: 0.4403 - val_loss: 1.1319 - val_acc: 0.5169 - val_mean_absolute_error: 0.3574 - val_mean_squared_error: 0.2157 - val_f1_m: 0.4528\n",
      "Epoch 19/30\n",
      "944/944 [==============================] - 1s 634us/step - loss: 0.9435 - acc: 0.5328 - mean_absolute_error: 0.3611 - mean_squared_error: 0.1860 - f1_m: 0.4186 - val_loss: 1.0295 - val_acc: 0.6102 - val_mean_absolute_error: 0.3108 - val_mean_squared_error: 0.1809 - val_f1_m: 0.6019\n",
      "Epoch 20/30\n",
      "944/944 [==============================] - 1s 531us/step - loss: 0.9293 - acc: 0.5519 - mean_absolute_error: 0.3483 - mean_squared_error: 0.1799 - f1_m: 0.4565 - val_loss: 1.0692 - val_acc: 0.5085 - val_mean_absolute_error: 0.3548 - val_mean_squared_error: 0.2058 - val_f1_m: 0.4655\n",
      "Epoch 21/30\n",
      "944/944 [==============================] - 0s 493us/step - loss: 0.9700 - acc: 0.5445 - mean_absolute_error: 0.3546 - mean_squared_error: 0.1856 - f1_m: 0.4523 - val_loss: 1.5457 - val_acc: 0.3814 - val_mean_absolute_error: 0.3939 - val_mean_squared_error: 0.2891 - val_f1_m: 0.3752\n",
      "Epoch 22/30\n",
      "944/944 [==============================] - 1s 667us/step - loss: 0.9664 - acc: 0.5424 - mean_absolute_error: 0.3582 - mean_squared_error: 0.1866 - f1_m: 0.4325 - val_loss: 1.0807 - val_acc: 0.5508 - val_mean_absolute_error: 0.3549 - val_mean_squared_error: 0.2117 - val_f1_m: 0.5330\n",
      "Epoch 23/30\n",
      "944/944 [==============================] - 0s 486us/step - loss: 0.8920 - acc: 0.5646 - mean_absolute_error: 0.3468 - mean_squared_error: 0.1739 - f1_m: 0.4694 - val_loss: 0.9513 - val_acc: 0.5847 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1842 - val_f1_m: 0.5673\n",
      "Epoch 24/30\n",
      "944/944 [==============================] - 0s 486us/step - loss: 0.8681 - acc: 0.5689 - mean_absolute_error: 0.3421 - mean_squared_error: 0.1714 - f1_m: 0.4812 - val_loss: 1.1772 - val_acc: 0.4915 - val_mean_absolute_error: 0.3734 - val_mean_squared_error: 0.2273 - val_f1_m: 0.4665\n",
      "Epoch 25/30\n",
      "944/944 [==============================] - 1s 686us/step - loss: 0.9181 - acc: 0.5689 - mean_absolute_error: 0.3436 - mean_squared_error: 0.1786 - f1_m: 0.4821 - val_loss: 1.2059 - val_acc: 0.4873 - val_mean_absolute_error: 0.3612 - val_mean_squared_error: 0.2346 - val_f1_m: 0.4669\n",
      "Epoch 26/30\n",
      "944/944 [==============================] - 0s 484us/step - loss: 0.8567 - acc: 0.5784 - mean_absolute_error: 0.3381 - mean_squared_error: 0.1687 - f1_m: 0.4761 - val_loss: 1.3252 - val_acc: 0.4619 - val_mean_absolute_error: 0.3678 - val_mean_squared_error: 0.2518 - val_f1_m: 0.4492\n",
      "Epoch 27/30\n",
      "944/944 [==============================] - 1s 579us/step - loss: 0.9606 - acc: 0.5561 - mean_absolute_error: 0.3450 - mean_squared_error: 0.1845 - f1_m: 0.4570 - val_loss: 1.4835 - val_acc: 0.6398 - val_mean_absolute_error: 0.2946 - val_mean_squared_error: 0.1951 - val_f1_m: 0.6360\n",
      "Epoch 28/30\n",
      "944/944 [==============================] - 1s 615us/step - loss: 0.8671 - acc: 0.5890 - mean_absolute_error: 0.3328 - mean_squared_error: 0.1681 - f1_m: 0.5045 - val_loss: 0.9113 - val_acc: 0.6314 - val_mean_absolute_error: 0.3103 - val_mean_squared_error: 0.1710 - val_f1_m: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "944/944 [==============================] - 0s 497us/step - loss: 0.8398 - acc: 0.5805 - mean_absolute_error: 0.3308 - mean_squared_error: 0.1661 - f1_m: 0.5024 - val_loss: 1.0377 - val_acc: 0.6144 - val_mean_absolute_error: 0.2933 - val_mean_squared_error: 0.1751 - val_f1_m: 0.6315\n",
      "Epoch 30/30\n",
      "944/944 [==============================] - 1s 613us/step - loss: 0.8138 - acc: 0.6049 - mean_absolute_error: 0.3219 - mean_squared_error: 0.1603 - f1_m: 0.5400 - val_loss: 1.2083 - val_acc: 0.5424 - val_mean_absolute_error: 0.3043 - val_mean_squared_error: 0.2154 - val_f1_m: 0.5434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb09e6e2748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, nb_epoch=30, batch_size=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8805410e-01, 1.1120364e-02, 8.2555437e-04],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [9.8385274e-01, 1.5235739e-02, 9.1151951e-04],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [9.8017597e-01, 5.9934468e-03, 1.3830588e-02],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [2.6489517e-01, 3.8104028e-01, 3.5406455e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [9.4500464e-01, 4.1766617e-02, 1.3228737e-02],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01],\n",
       "       [3.1520617e-01, 2.8319022e-01, 4.0160367e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X[0:100])\n",
    "prediction /= prediction.sum(axis=1).reshape((-1, 1))\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
